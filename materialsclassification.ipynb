{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jinyoungkim0214/portfolio/blob/main/materialsclassification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "import하기"
      ],
      "metadata": {
        "id": "AppKwEu4sVcz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# apache 2.0 - 코드에서 어떤 부분 수정했는지 명시해야 함"
      ],
      "metadata": {
        "id": "0J3bDHSZ4eCu"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "9VW25cvvre8I",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 341
        },
        "outputId": "625bb309-1475-4c5a-96d9-124bee7b0407"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "mount failed",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-b6ced5cbe1ca>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;31m# 이미지 class 47개\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;31m# 구글 드라이브 마운트\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36mmount\u001b[0;34m(mountpoint, force_remount, timeout_ms, readonly)\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_ms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m120000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreadonly\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m   \u001b[0;34m\"\"\"Mount your Google Drive at the specified mountpoint path.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m   return _mount(\n\u001b[0m\u001b[1;32m    101\u001b[0m       \u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m       \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mforce_remount\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36m_mount\u001b[0;34m(mountpoint, force_remount, timeout_ms, ephemeral, readonly)\u001b[0m\n\u001b[1;32m    277\u001b[0m             \u001b[0;34m'https://research.google.com/colaboratory/faq.html#drive-timeout'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    278\u001b[0m         )\n\u001b[0;32m--> 279\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'mount failed'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mextra_reason\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    280\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mcase\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    281\u001b[0m       \u001b[0;31m# Terminate the DriveFS binary before killing bash.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: mount failed"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import os.path\n",
        "import torch\n",
        "import torch.utils.data as data\n",
        "from PIL import Image\n",
        "from torchvision import transforms\n",
        "from google.colab import drive  # 구글 드라이브 마운트용\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# 이미지 class 47개\n",
        "# 구글 드라이브 마운트\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def find_classes(dir):\n",
        "    classes = [d for d in os.listdir(dir) if os.path.isdir(os.path.join(dir, d))]\n",
        "    classes.sort()\n",
        "    class_to_idx = {classes[i]: i for i in range(len(classes))}\n",
        "    return classes, class_to_idx\n",
        "\n",
        "\n",
        "def make_dataset(txtnames, datadir, class_to_idx): #리스트 안의 이미지 경로랑 label\n",
        "    images = []\n",
        "    labels = []\n",
        "    for txtname in txtnames:\n",
        "        with open(txtname, 'r') as lines:\n",
        "            for line in lines:\n",
        "                classname = line.split('/')[0]\n",
        "                _img = os.path.join(datadir, 'images', line.strip())\n",
        "                assert os.path.isfile(_img)\n",
        "                images.append(_img)\n",
        "                labels.append(class_to_idx[classname])\n",
        "\n",
        "    return images, labels\n",
        "\n",
        "\n",
        "class DTDDataloader(data.Dataset): #이미지랑 label이 각각 저장이 됨 #경로랑 label을 이미지랑 label에 저장 (용량을 줄이고 싶어서, 이미지는 경로만, label은 텍스트니까 그대로 해도 괜찮다)\n",
        "    def __init__(self, DATASET_PATH, split, transform=None, train=True):\n",
        "        classes, class_to_idx = find_classes(os.path.join(DATASET_PATH, 'images'))\n",
        "        self.classes = classes\n",
        "        self.class_to_idx = class_to_idx\n",
        "        self.train = train\n",
        "        self.transform = transform\n",
        "\n",
        "        if train:\n",
        "            filename = [os.path.join(DATASET_PATH, 'labels/train' + split + '.txt'),\n",
        "                        os.path.join(DATASET_PATH, 'labels/val' + split + '.txt')]\n",
        "        else:\n",
        "            filename = [os.path.join(DATASET_PATH, 'labels/test' + split + '.txt')]\n",
        "\n",
        "        self.images, self.labels = make_dataset(filename, DATASET_PATH, class_to_idx)\n",
        "        assert (len(self.images) == len(self.labels))\n",
        "\n",
        "    def __getitem__(self, index):#이미지의 인덱스가 0~ 이미지 경로 오픈해서 rgb로 변환\n",
        "        _img = Image.open(self.images[index]).convert('RGB') #여기에rgb저장\n",
        "        _label = self.labels[index]\n",
        "        if self.transform is not None:\n",
        "            _img = self.transform(_img)\n",
        "\n",
        "        return _img, _label\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.images)\n",
        "\n",
        "\n",
        "class Dataloder():\n",
        "    def __init__(self, DATASET_PATH, split, batch_size):\n",
        "        normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                                         std=[0.229, 0.224, 0.225]) #정규화\n",
        "        transform_train = transforms.Compose([\n",
        "            transforms.Resize(256),\n",
        "            transforms.RandomResizedCrop(224),\n",
        "            transforms.RandomHorizontalFlip(),\n",
        "            transforms.RandomVerticalFlip(),\n",
        "            transforms.ToTensor(),\n",
        "            normalize,\n",
        "        ])\n",
        "        transform_test = transforms.Compose([\n",
        "            #transforms.Resize(256),\n",
        "            #transforms.CenterCrop(224),\n",
        "            transforms.Resize(64),\n",
        "            #transforms.CenterCrop(32),\n",
        "            transforms.ToTensor(),\n",
        "            normalize,\n",
        "        ])\n",
        "\n",
        "        trainset = DTDDataloader(DATASET_PATH, split, transform_train, train=True)\n",
        "        testset = DTDDataloader(DATASET_PATH, split, transform_test, train=False)\n",
        "\n",
        "        kwargs = {'num_workers': 8, 'pin_memory': True}\n",
        "        trainloader = torch.utils.data.DataLoader(trainset, batch_size=\n",
        "        batch_size, shuffle=True, **kwargs)\n",
        "        testloader = torch.utils.data.DataLoader(testset, batch_size=\n",
        "        batch_size, shuffle=False, **kwargs)\n",
        "        self.classes = trainset.classes\n",
        "        self.trainloader = trainloader\n",
        "        self.testloader = testloader\n",
        "\n",
        "    def getloader(self): #tensor로 바꿔주고 학습시키기\n",
        "        return self.classes, self.trainloader, self.testloader"
      ],
      "metadata": {
        "id": "1vX7P2Vhm-Wf"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "전처리(pre-processing)\n",
        "* 학습 data, train, validation, test를 어떻게 나눌 건지 (데이터 6:2:2를 어떻게 나눌 건지?) - 총 수천~수만 장은 필요함"
      ],
      "metadata": {
        "id": "s9F7mf3TsX1A"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "dataset 불러오기"
      ],
      "metadata": {
        "id": "AKil77E6sXYE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/drive/MyDrive\n",
        "!unzip \"dataset.zip\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WDUuDST1rcNH",
        "outputId": "19351af6-21f1-422b-ffd7-734772177fc9"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive\n",
            "unzip:  cannot find or open dataset.zip, dataset.zip.zip or dataset.zip.ZIP.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 데이터셋 경로 설정 (구글 드라이브 내 dataset/dtd 폴더)\n",
        "DATASET_PATH = '/content/drive/MyDrive/dataset/dtd'\n",
        "split = '1'\n",
        "batch_size = 32"
      ],
      "metadata": {
        "id": "8NO3TP91pmm5"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 예시: 배치 사이즈 32, split=1로 데이터로더 생성\n",
        "dataloader = Dataloder(DATASET_PATH, batch_size=32, split='1')\n",
        "classes, trainloader, testloader = dataloader.getloader()\n",
        "\n",
        "# 데이터로더 테스트\n",
        "for images, labels in trainloader:\n",
        "    print(images.shape, labels.shape)\n",
        "    break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 379
        },
        "id": "37YvoH1wm-58",
        "outputId": "b22306d1-16e4-4870-d117-4f62b00937a2"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: '/content/drive/MyDrive/dataset/dtd/images'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-22-a90e50fadd23>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# 예시: 배치 사이즈 32, split=1로 데이터로더 생성\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdataloader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataloder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDATASET_PATH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msplit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'1'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mclasses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtestloader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataloader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetloader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# 데이터로더 테스트\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-16-33dd28389dd7>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, DATASET_PATH, split, batch_size)\u001b[0m\n\u001b[1;32m     71\u001b[0m         ])\n\u001b[1;32m     72\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m         \u001b[0mtrainset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDTDDataloader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDATASET_PATH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msplit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransform_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m         \u001b[0mtestset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDTDDataloader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDATASET_PATH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msplit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransform_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-16-33dd28389dd7>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, DATASET_PATH, split, transform, train)\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mDTDDataloader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m#이미지랑 label이 각각 저장이 됨 #경로랑 label을 이미지랑 label에 저장 (용량을 줄이고 싶어서, 이미지는 경로만, label은 텍스트니까 그대로 해도 괜찮다)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDATASET_PATH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msplit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m         \u001b[0mclasses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_to_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfind_classes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDATASET_PATH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'images'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclasses\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclass_to_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclass_to_idx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-16-33dd28389dd7>\u001b[0m in \u001b[0;36mfind_classes\u001b[0;34m(dir)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mfind_classes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mclasses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0md\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0md\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdir\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mclasses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mclass_to_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mclasses\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclasses\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mclasses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_to_idx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/drive/MyDrive/dataset/dtd/images'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "network 설계\n",
        "* 어떤 network를 사용할 건지\n",
        "* 차원 계산"
      ],
      "metadata": {
        "id": "G_7QY8JbsYFw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from typing import Dict, List, Tuple, Union\n",
        "\n",
        "class BasicBlock(nn.Module):\n",
        "    expansion = 1\n",
        "    def __init__(self, in_planes: int, out_planes: int, stride: int = 1, downsample: nn.Module = None,\n",
        "                 padding_mode: str = 'constant'):\n",
        "        super().__init__()\n",
        "        self.conv1 = self._make_conv(in_planes, out_planes, kernel_size=3, stride=stride,\n",
        "                                     padding=1, padding_mode=padding_mode)\n",
        "        self.bn1 = nn.BatchNorm2d(out_planes)\n",
        "        self.conv2 = self._make_conv(out_planes, out_planes, kernel_size=3, stride=1,\n",
        "                                     padding=1, padding_mode=padding_mode)\n",
        "        self.bn2 = nn.BatchNorm2d(out_planes)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.downsample = downsample\n",
        "        self.stride = stride\n",
        "\n",
        "    def _make_conv(self, in_ch, out_ch, kernel_size, stride, padding, padding_mode):\n",
        "        conv = nn.Conv2d(in_ch, out_ch, kernel_size=kernel_size, stride=stride,\n",
        "                         padding=padding, bias=False)\n",
        "        return conv\n",
        "\n",
        "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        identity = x\n",
        "        out = self.conv1(x)\n",
        "        out = self.bn1(out)\n",
        "        out = self.relu(out)\n",
        "        out = self.conv2(out)\n",
        "        out = self.bn2(out)\n",
        "        if self.downsample is not None:\n",
        "            identity = self.downsample(x)\n",
        "        out += identity\n",
        "        out = self.relu(out)\n",
        "        return out\n",
        "\n",
        "class Bottleneck(nn.Module): #conv여러개 -> bottleneck 한 덩어리 -> 여러개 -> Resnet\n",
        "    expansion = 4\n",
        "    def __init__(self, in_planes: int, out_planes: int, stride: int = 1, downsample: nn.Module = None,\n",
        "                 padding_mode: str = 'constant'):\n",
        "        super().__init__()\n",
        "        mid_planes = out_planes\n",
        "        self.conv1 = self._make_conv(in_planes, mid_planes, kernel_size=1, stride=1,\n",
        "                                     padding=0, padding_mode=padding_mode)\n",
        "        self.bn1 = nn.BatchNorm2d(mid_planes)\n",
        "        self.conv2 = self._make_conv(mid_planes, mid_planes, kernel_size=3, stride=stride,\n",
        "                                     padding=1, padding_mode=padding_mode)\n",
        "        self.bn2 = nn.BatchNorm2d(mid_planes)\n",
        "        self.conv3 = self._make_conv(mid_planes, out_planes * self.expansion, kernel_size=1, stride=1,\n",
        "                                     padding=0, padding_mode=padding_mode)\n",
        "        self.bn3 = nn.BatchNorm2d(out_planes * self.expansion)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.downsample = downsample\n",
        "        self.stride = stride\n",
        "\n",
        "    def _make_conv(self, in_ch, out_ch, kernel_size, stride, padding, padding_mode):\n",
        "        conv = nn.Conv2d(in_ch, out_ch, kernel_size=kernel_size, stride=stride,\n",
        "                         padding=padding, bias=False)\n",
        "        return conv\n",
        "\n",
        "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        identity = x\n",
        "        out = self.conv1(x)\n",
        "        out = self.bn1(out)\n",
        "        out = self.relu(out)\n",
        "        out = self.conv2(out)\n",
        "        out = self.bn2(out)\n",
        "        out = self.relu(out)\n",
        "        out = self.conv3(out)\n",
        "        out = self.bn3(out)\n",
        "        if self.downsample is not None:\n",
        "            identity = self.downsample(x)\n",
        "        out += identity\n",
        "        out = self.relu(out)\n",
        "        return out\n",
        "\n",
        "resnet_cfgs: Dict[str, Tuple[Union[BasicBlock, Bottleneck], List[int]]] = {\n",
        "    \"resnet18\":  (BasicBlock,  [2, 2, 2, 2]), #bottleneck보다 가벼운게 basicblock\n",
        "    \"resnet34\":  (BasicBlock,  [3, 4, 6, 3]), #(3+4+6+3)*2+1+1 (맨 마지막 부분 2개)\n",
        "\n",
        "    \"resnet50\":  (Bottleneck, [3, 4, 6, 3]), #여기서는 34로 돌림\n",
        "    \"resnet101\":  (Bottleneck, [3, 4, 23, 3]), #(3+4+23+3)*3+1+1=101\n",
        "    \"resnet152\":  (Bottleneck, [3, 8, 36, 3]) #(3+8+36+3)*3+1+1=152\n",
        "    }\n",
        "\n",
        "\n",
        "def make_resnet_layers(\n",
        "    resnet_type: str = \"resnet18\",\n",
        "    in_channels: int = 1,\n",
        "    padding_mode: str = \"constant\"\n",
        ") -> nn.Module:\n",
        "    \"\"\"\n",
        "    Modified to return a module that can output intermediate layers.\n",
        "    \"\"\"\n",
        "    block_class, layer_cfg = resnet_cfgs[resnet_type]\n",
        "\n",
        "    class ResNetLayers(nn.Module):\n",
        "        def __init__(self):\n",
        "            super().__init__()\n",
        "            # Initial conv7x7 + BN + ReLU + MaxPool\n",
        "            self.conv1 = nn.Conv2d(in_channels, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
        "            self.bn1 = nn.BatchNorm2d(64)\n",
        "            self.relu = nn.ReLU(inplace=True)\n",
        "            self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
        "\n",
        "            # Define layers\n",
        "            self.layer1 = self._make_layer(block_class, 64, 64, layer_cfg[0], stride=1, padding_mode=padding_mode)\n",
        "            self.layer2 = self._make_layer(block_class, 64 * block_class.expansion, 128, layer_cfg[1], stride=2, padding_mode=padding_mode)\n",
        "            self.layer3 = self._make_layer(block_class, 128 * block_class.expansion, 256, layer_cfg[2], stride=2, padding_mode=padding_mode)\n",
        "            self.layer4 = self._make_layer(block_class, 256 * block_class.expansion, 512, layer_cfg[3], stride=2, padding_mode=padding_mode)\n",
        "\n",
        "        def _make_layer(self, block, in_ch, out_ch, num_blocks, stride, padding_mode):\n",
        "            downsample = None\n",
        "            if stride != 1 or in_ch != out_ch * block.expansion:\n",
        "                downsample = nn.Sequential(\n",
        "                    nn.Conv2d(in_ch, out_ch * block.expansion, kernel_size=1, stride=stride, bias=False),\n",
        "                    nn.BatchNorm2d(out_ch * block.expansion),\n",
        "                )\n",
        "            blocks = []\n",
        "            blocks.append(block(in_ch, out_ch, stride=stride, downsample=downsample, padding_mode=padding_mode))\n",
        "            in_ch = out_ch * block.expansion\n",
        "            for _ in range(1, num_blocks):\n",
        "                blocks.append(block(in_ch, out_ch, stride=1, downsample=None, padding_mode=padding_mode))\n",
        "            return nn.Sequential(*blocks)\n",
        "\n",
        "        def forward(self, x):\n",
        "            x = self.conv1(x)\n",
        "            x = self.bn1(x)\n",
        "            x = self.relu(x)\n",
        "            x = self.maxpool(x)\n",
        "            out1 = self.layer1(x)\n",
        "            out2 = self.layer2(out1)\n",
        "            out3 = self.layer3(out2)\n",
        "            out4 = self.layer4(out3)\n",
        "            return out4\n",
        "\n",
        "    return ResNetLayers()\n",
        "\n",
        "class ResNetFeatureExtractor(nn.Module):\n",
        "    \"\"\"\n",
        "    Modified to return outputs from layer1, layer2, layer3, and layer4.\n",
        "    Example:\n",
        "        model = ResNetFeatureExtractor(resnet_type='resnet18', in_channels=1)\n",
        "        outs = model(x)  # x: (B,1,192,96), outs: list of [B,64,96,48], [B,128,48,24], [B,256,24,12], [B,512,12,6]\n",
        "    \"\"\"\n",
        "    def __init__(\n",
        "        self,\n",
        "        resnet_type: str = \"resnet18\",\n",
        "        in_channels: int = 3,\n",
        "        padding_mode: str = 'constant'\n",
        "    ):\n",
        "        super().__init__()\n",
        "        assert resnet_type in resnet_cfgs, f\"Unsupported ResNet type: {resnet_type}\"\n",
        "\n",
        "        self.resnet_type = resnet_type\n",
        "        self.in_channels = in_channels\n",
        "        self.padding_mode = padding_mode\n",
        "        self.feature_extractor = make_resnet_layers(resnet_type, in_channels, padding_mode)\n",
        "        self._initialize_weights()\n",
        "\n",
        "    def forward(self, x: torch.Tensor) -> List[torch.Tensor]:\n",
        "        return self.feature_extractor(x)\n",
        "\n",
        "    def _initialize_weights(self) -> None:\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Conv2d):\n",
        "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
        "                if m.bias is not None:\n",
        "                    nn.init.constant_(m.bias, 0)\n",
        "            elif isinstance(m, nn.BatchNorm2d):\n",
        "                nn.init.constant_(m.weight, 1)\n",
        "                nn.init.constant_(m.bias, 0)\n",
        "            elif isinstance(m, nn.Linear):\n",
        "                nn.init.normal_(m.weight, 0, 0.01)\n",
        "                nn.init.constant_(m.bias, 0)\n"
      ],
      "metadata": {
        "id": "ZtToES5Xlxjr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class BaselineModel1(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        #self.fe = ResNetFeatureExtractor(resnet_type=\"resnet152\", in_channels=3) #resnetfeatureextractor: backbone부분\n",
        "        self.fe = ResNetFeatureExtractor(resnet_type=\"resnet101\", in_channels=3)\n",
        "        #self.fe = ResNetFeatureExtractor(resnet_type=\"resnet50\", in_channels=3)\n",
        "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
        "        self.fc = nn.Linear(2048, 47) #데이터셋에 맞게 수정하기 (클래스 47개)\n",
        "\n",
        "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        x = self.fe(x)\n",
        "        #여기서부터 head\n",
        "        x = self.avgpool(x)\n",
        "        print('avgpool shape:', x.shape)\n",
        "        x = torch.flatten(x, 1)\n",
        "        print('flatten shape:', x.shape)\n",
        "        x = self.fc(x)\n",
        "        print('fc shape:', x.shape)\n",
        "\n",
        "        return x\n",
        "\n",
        "net=BaselineModel1()"
      ],
      "metadata": {
        "id": "jKjZBEOYzBWX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "parameter 정의\n",
        "* 어떤 loss를 쓸 건지\n",
        "* 어떤 optimizer를 쓸 건지\n",
        "* 학습률은 몇으로 할 건지\n",
        "* 몇 epoch을 학습시킬 건지"
      ],
      "metadata": {
        "id": "ntyRAClusYSM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(net.parameters(), lr=0.005, momentum=0.9)  # Learning rate: 학습률. 한 번의 optimizer step에서 얼마나 멀리 갈지."
      ],
      "metadata": {
        "id": "OUVepM7Xzdau"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "      \"\"\"Train Config\"\"\"\n",
        "      C.lr = 1e-2\n",
        "      C.lr_decay = 40\n",
        "      C.momentum = 0.9\n",
        "      C.weight_decay = 1e-4\n",
        "      C.batch_size = 64\n",
        "      C.start_epoch = 1\n",
        "      C.nepochs = 100\n",
        "      C.eval = False\n",
        "      C.split = '1'\n",
        "\n",
        "      C.cuda = True\n",
        "      C.gpu = '0'\n",
        "      C.resume = False\n",
        "      C.momentum = 0.9\n",
        "      C.weight_decay = 1e-4"
      ],
      "metadata": {
        "id": "oAqazShLtLxz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "train(학습)"
      ],
      "metadata": {
        "id": "BonNJffXsjpI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "training_loss_history = []\n",
        "test_loss_history = []"
      ],
      "metadata": {
        "id": "1IX0i_fZzicP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Dataloder():\n",
        "    def __init__(self, DATASET_PATH, split, batch_size):\n",
        "        normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                                         std=[0.229, 0.224, 0.225])\n",
        "\n",
        "        # --- 학습용(증강 그대로) ---\n",
        "        transform_train = transforms.Compose([\n",
        "            transforms.Resize(256),\n",
        "            transforms.RandomResizedCrop(224),\n",
        "            transforms.RandomHorizontalFlip(),\n",
        "            transforms.RandomVerticalFlip(),\n",
        "            transforms.ToTensor(),\n",
        "            normalize,\n",
        "        ])\n",
        "\n",
        "        # --- 🔴 여기 수정: 테스트·검증용도 224×224로 고정 🔴 ---\n",
        "        transform_test = transforms.Compose([\n",
        "            transforms.Resize(256),       # 긴 변 기준 256\n",
        "            transforms.CenterCrop(224),   # 가운데서 224×224 잘라내기\n",
        "            transforms.ToTensor(),\n",
        "            normalize,\n",
        "        ])\n",
        "        # -------------------------------------------------------\n",
        "\n",
        "        trainset = DTDDataloader(DATASET_PATH, split, transform_train, train=True)\n",
        "        testset  = DTDDataloader(DATASET_PATH, split, transform_test,  train=False)\n",
        "\n",
        "        kwargs = {'num_workers': 8, 'pin_memory': True}\n",
        "        trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,\n",
        "                                                  shuffle=True,  **kwargs)\n",
        "        testloader  = torch.utils.data.DataLoader(testset,  batch_size=batch_size,\n",
        "                                                  shuffle=False, **kwargs)\n",
        "\n",
        "        self.classes     = trainset.classes\n",
        "        self.trainloader = trainloader\n",
        "        self.testloader  = testloader\n"
      ],
      "metadata": {
        "id": "S_bmY0vMtzvX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(2):  # 전체 데이터셋을 몇 번 반복할 건지\n",
        "\n",
        "    running_loss = 0.0\n",
        "    for i, data in enumerate(trainloader, 0):\n",
        "        # trainloader로부터 데이터와 라벨을 받아옵니다.\n",
        "        inputs, labels = data\n",
        "\n",
        "        # 매 반복마다 이전 gradient를 한 번 지워줍니다.\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # 모델에 데이터 넣어서 forward 해주고\n",
        "        # backprop으로 이번 input에 대해 gradient를 계산해주고\n",
        "        # optimizer가 gradient descent 1스텝 진행\n",
        "        outputs = net(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # 결과치 화면에 뿌려주기\n",
        "        running_loss += loss.item()\n",
        "        if i % 10 == 9:    # 200 미니배치마다 출력 i=0~199: 200개가 통과; 200개마다 프린트해서 보자 #역전파하고 있으니까 학습데이터에 대한 loss는 계속 줄어듦\n",
        "            print('[%d, %5d] loss: %.3f' %\n",
        "                  (epoch + 1, i + 1, running_loss / 200))\n",
        "\n",
        "            # 나중에 시각화를 위해 중간중간 따로 loss값 저장\n",
        "            training_loss_history.append(running_loss / 200)\n",
        "\n",
        "            with torch.no_grad():\n",
        "                running_test_loss = 0.0\n",
        "                for i, test_data in enumerate(testloader, 0):\n",
        "                    test_images, test_labels = test_data\n",
        "                    test_outputs = net(test_images)\n",
        "                    test_loss = criterion(test_outputs, test_labels)\n",
        "                    running_test_loss += test_loss.item()\n",
        "\n",
        "                test_loss_history.append(running_test_loss / i)\n",
        "\n",
        "            running_loss = 0.0\n",
        "\n",
        "print('학습 끝!')"
      ],
      "metadata": {
        "id": "uB57M4D5zmWv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6658df6d-07b4-4741-da1a-f127787eb88e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "avgpool shape: torch.Size([32, 2048, 1, 1])\n",
            "flatten shape: torch.Size([32, 2048])\n",
            "fc shape: torch.Size([32, 47])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "test"
      ],
      "metadata": {
        "id": "gwIfhucMsj38"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(training_loss_history, label=\"Training Loss\")\n",
        "plt.plot(test_loss_history, 'r', label=\"Test Loss\")\n",
        "plt.title('Training & Test Loss', fontsize=20)\n",
        "plt.xlabel('Iteration',fontsize=16)\n",
        "plt.ylabel('Loss',fontsize=16)\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "YPvYv-zBsj_-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "PATH = './dtd_net.pth'\n",
        "torch.save(net.state_dict(), PATH)"
      ],
      "metadata": {
        "id": "VlN-U72ywV3z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "classes, train_loader, test_loader = Dataloder(DATASET_PATH, batch_size, split).getloader()\n",
        "\n",
        "dataiter = iter(test_loader)\n",
        "images, labels = dataiter.next()\n",
        "\n",
        "imshow(torchvision.utils.make_grid(images))"
      ],
      "metadata": {
        "id": "BUiK6iT3wWpI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "net = Net()\n",
        "net.load_state_dict(torch.load(PATH))"
      ],
      "metadata": {
        "id": "qzs0MhQIytFw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "outputs = net(images)\n",
        "outputs"
      ],
      "metadata": {
        "id": "VJYXQymhyuz3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "_, predicted = torch.max(outputs, 1)  # 1번째 차원(=각 row)에서 각각 max인 값과 해당 index를 뽑아옵니다.\n",
        "\n",
        "print('모델 예측: ', ', '.join('%5s' % classes[predicted[j]]\n",
        "                              for j in range(4)))"
      ],
      "metadata": {
        "id": "1x4uXoRNyzJ9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 원래 이미지랑 같이 볼까요?\n",
        "imshow(torchvision.utils.make_grid(images[:4]))\n",
        "print('실제 정답: ', ', '.join('%5s' % classes[labels[j]] for j in range(4)))\n",
        "print('모델 예측: ', ', '.join('%5s' % classes[predicted[j]]\n",
        "                              for j in range(4)))"
      ],
      "metadata": {
        "id": "bQKiXZehy1fK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "    for data in testloader:\n",
        "        images, labels = data\n",
        "        outputs = net(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "print('10000개의 테스트 이미지에 대한 정답률: %d %%' % (\n",
        "    100 * correct / total))"
      ],
      "metadata": {
        "id": "B79vZ5Auy60d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class_correct = list(0. for i in range(47))\n",
        "class_total = list(0. for i in range(47))\n",
        "\n",
        "with torch.no_grad():  # 매우매우 중요!  테스트셋으로 backprop을 하면 안 됨.\n",
        "    for data in testloader:\n",
        "        images, labels = data\n",
        "        outputs = net(images)\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        c = (predicted == labels).squeeze()\n",
        "        for i in range(4):\n",
        "            label = labels[i]\n",
        "            class_correct[label] += c[i].item()\n",
        "            class_total[label] += 1\n",
        "\n",
        "\n",
        "for i in range(47):\n",
        "    print('%5s 클래스의 정답률 : %2d %%' % (\n",
        "        classes[i], 100 * class_correct[i] / class_total[i]))"
      ],
      "metadata": {
        "id": "FCMx5F-my-Jf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#여기 수정!!!!!!!\n",
        "\n",
        "# 데이터 로더 준비\n",
        "classes, train_loader, test_loader = Dataloader(DATASET_PATH, batch_size, split).getloader()\n",
        "\n",
        "# 모델·손실·최적화기 설정\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(net.parameters(), lr=learning_rate)\n",
        "\n",
        "# 학습 기록용\n",
        "training_loss_history = []\n",
        "test_loss_history = []\n",
        "\n",
        "# 최고 정확도 추적\n",
        "best_acc = 0.0\n",
        "\n",
        "for epoch in range(1, num_epochs+1):\n",
        "\n",
        "    # 평가 단계\n",
        "    net.eval()\n",
        "    running_test_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in test_loader:\n",
        "            outputs = net(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            running_test_loss += loss.item()\n",
        "            _, preds = torch.max(outputs, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (preds == labels).sum().item()\n",
        "    avg_test_loss = running_test_loss / len(test_loader)\n",
        "    test_loss_history.append(avg_test_loss)\n",
        "    acc = 100.0 * correct / total\n",
        "\n",
        "    # 결과 출력\n",
        "    print(f'Epoch {epoch}/{num_epochs} — Train Loss: {avg_train_loss:.4f}, '\n",
        "          f'Test Loss: {avg_test_loss:.4f}, Test Acc: {acc:.2f}%')\n",
        "\n",
        "    # 최고 정확도 갱신 및 모델 저장\n",
        "    if acc > best_acc:\n",
        "        best_acc = acc\n",
        "        torch.save(net.state_dict(), 'best_model.pth')\n",
        "        print(f'▶ New Best Accuracy! {best_acc:.2f}% 에포크 {epoch}에서 달성, 모델 저장 완료.')\n",
        "\n",
        "#학습 곡선 시각화\n",
        "plt.plot(training_loss_history, label=\"Training Loss\")\n",
        "plt.plot(test_loss_history, 'r', label=\"Test Loss\")\n",
        "plt.title('Training & Test Loss', fontsize=20)\n",
        "plt.xlabel('Epoch', fontsize=16)\n",
        "plt.ylabel('Loss', fontsize=16)\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "# 저장된 최고 모델 로드 및 샘플 예측\n",
        "net_best = Net()\n",
        "net_best.load_state_dict(torch.load('best_model.pth'))\n",
        "net_best.eval()\n",
        "\n",
        "dataiter = iter(test_loader)\n",
        "images, labels = dataiter.next()\n",
        "imshow(torchvision.utils.make_grid(images))\n",
        "\n",
        "outputs = net_best(images)\n",
        "_, predicted = torch.max(outputs, 1)\n",
        "\n",
        "print('실제 정답: ', ', '.join(f'{classes[l]}' for l in labels[:4]))\n",
        "print('모델 예측: ', ', '.join(f'{classes[p]}' for p in predicted[:4]))"
      ],
      "metadata": {
        "id": "v9GFhzdGEqIl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "분석\n",
        "* 평가 지표\n",
        "* 비교 모델 (다른 모델과의 비교 분석)\n",
        "* graph/표 구성\n",
        "tip: 벤치마크 - 기존에 어떤 연구가 있는지 살펴보고, 그대로 진행하되 성능을 올릴 방법 모색하기 - 모델 하나 잡아서 그게 어떤 data를 썼는지 살펴보기 (논문) : 코드 가져와서 수정하는 방식으로"
      ],
      "metadata": {
        "id": "bDFZQk_qskIE"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0DYer-ehskOf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "만약에 loss를 프린트했는데 train loss는 떨어지는데 test loss는 안 떨어지는 거: overfitting -> data augmentation을 하거나 (generalization 성능이 떨어지는 것임), early stopping(epoch 줄이기), dropout layer 추가하기\n",
        "\n",
        "train loss가 진동: underfitting: a(learning rate)가 너무 큰 경우 -> 줄이기, loss function을 다시 체크, network 설계를 다시 뜯어보기\n",
        "\n",
        "학습이 너무 오래 걸림(loss가 둘 다 떨어지긴 하는데): learning rate scheduler 사용해서 처음에는 a를 크게 했다가 학습이 진행될수록 감소하도록 설계 cosineannealinglr\n",
        "optimizer을 아담에서 아담W로\n",
        "batch normalization 추가"
      ],
      "metadata": {
        "id": "J5G4PWt--GfW"
      }
    }
  ]
}